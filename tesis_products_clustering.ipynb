{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tesis_products_clustering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joenvihe/ejemplos_machine_learning/blob/master/tesis_products_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFQMPGO3ZnLT",
        "colab_type": "text"
      },
      "source": [
        "## **Conexión al Google Drive**\n",
        "\n",
        "Nos conectamos al google drive donde tenemos nuestra fuente de información"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1fticzTZge9",
        "colab_type": "code",
        "outputId": "ed557285-d460-4165-e62a-837b7e8558b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Nos conectamos al google drive para obtner el dataset\n",
        "from google.colab import drive\n",
        "# obtener la autorizacion\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPL08R2NZkvJ",
        "colab_type": "code",
        "outputId": "bec7826d-1bae-4e6e-92a0-51e495ee7224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# nos ubicamos en la carpeta donde se encuentra el DATASET\n",
        "%cd /content/drive/'My Drive'/UNIR/TESIS"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/UNIR/TESIS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0kxFlYrZ7ET",
        "colab_type": "text"
      },
      "source": [
        "## **Instalación de módulos**\n",
        "\n",
        "Instalamos todos los modulos necesarios de python para el desarrollo de la tesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQv_6O0uZwAk",
        "colab_type": "code",
        "outputId": "f6fffef9-ec4a-4737-8236-4f951577b16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install translate\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting translate\n",
            "  Downloading https://files.pythonhosted.org/packages/85/b2/2ea329a07bbc0c7227eef84ca89ffd6895e7ec237d6c0b26574d56103e53/translate-3.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from translate) (7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from translate) (2.21.0)\n",
            "Collecting tox (from translate)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/21/66868fc9074e366d0dc6952c53c918230e772fd662e69b331bac7a67fcbe/tox-3.13.2-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from translate) (4.2.6)\n",
            "Collecting pre-commit (from translate)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/d4/ea2c1b98401a3afc57f3e93ad993abba1fe34643e29e8fe5a7628bcdc7c2/pre_commit-1.18.0-py2.py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 17.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->translate) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->translate) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->translate) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->translate) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata<1,>=0.12 in /usr/local/lib/python3.6/dist-packages (from tox->translate) (0.19)\n",
            "Collecting pluggy<1,>=0.12.0 (from tox->translate)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/ee/de89e0582276e3551df3110088bf20844de2b0e7df2748406876cc78e021/pluggy-0.12.0-py2.py3-none-any.whl\n",
            "Collecting toml>=0.9.4 (from tox->translate)\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from tox->translate) (3.0.12)\n",
            "Requirement already satisfied: py<2,>=1.4.17 in /usr/local/lib/python3.6/dist-packages (from tox->translate) (1.8.0)\n",
            "Collecting virtualenv>=14.0.0 (from tox->translate)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/9e/df208b2baad146fe3fbe750eacadd6e49bcf2f2c3c1117b7192a7b28aec4/virtualenv-16.7.2-py2.py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 52.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from tox->translate) (1.12.0)\n",
            "Requirement already satisfied: packaging>=14 in /usr/local/lib/python3.6/dist-packages (from tox->translate) (19.1)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->translate)\n",
            "  Downloading https://files.pythonhosted.org/packages/00/6e/ed417bd1ed417ab3feada52d0c89ab0ed87d150f91590badf84273e047c9/nodeenv-1.3.3.tar.gz\n",
            "Collecting importlib-resources; python_version < \"3.7\" (from pre-commit->translate)\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/f7/b4aa02cdd3ee7ebba375969d77c00826aa15c5db84247d23c89522dccbfa/importlib_resources-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from pre-commit->translate) (3.13)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->translate)\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/ff/2e6bcaff26058200717c469a0910da96c89bb00e9cc31b68aa0bfc9b1b0d/cfgv-2.0.1-py2.py3-none-any.whl\n",
            "Collecting identify>=1.0.0 (from pre-commit->translate)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/f7/0ad891a459ee50e8774636798ce00e0b445addd8555661da9dbb546676a6/identify-1.4.5-py2.py3-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 29.3MB/s \n",
            "\u001b[?25hCollecting aspy.yaml (from pre-commit->translate)\n",
            "  Downloading https://files.pythonhosted.org/packages/99/ce/78be097b00817ccf02deaf481eb7a603eecee6fa216e82fa7848cd265449/aspy.yaml-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<1,>=0.12->tox->translate) (0.5.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from packaging>=14->tox->translate) (19.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=14->tox->translate) (2.4.2)\n",
            "Building wheels for collected packages: nodeenv\n",
            "  Building wheel for nodeenv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nodeenv: filename=nodeenv-1.3.3-cp36-none-any.whl size=21349 sha256=342b3234380628b3b5d2bac9277c23be375364231cc54a7bc512e1a88e1f1b78\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/6c/23/eb26369b77904c8963fae9e64338b0f0b948b4d59710760834\n",
            "Successfully built nodeenv\n",
            "\u001b[31mERROR: pytest 3.6.4 has requirement pluggy<0.8,>=0.5, but you'll have pluggy 0.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pluggy, toml, virtualenv, tox, nodeenv, importlib-resources, cfgv, identify, aspy.yaml, pre-commit, translate\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "Successfully installed aspy.yaml-1.3.0 cfgv-2.0.1 identify-1.4.5 importlib-resources-1.0.2 nodeenv-1.3.3 pluggy-0.12.0 pre-commit-1.18.0 toml-0.10.0 tox-3.13.2 translate-3.5.0 virtualenv-16.7.2\n",
            "Collecting es_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.1.0/es_core_news_sm-2.1.0.tar.gz#egg=es_core_news_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.1.0/es_core_news_sm-2.1.0.tar.gz (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 759kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.1.0-cp36-none-any.whl size=11111557 sha256=4c7e183fd5cd33d48a10983b595438a836a0bbdc457971c5d81e5978f22dc2a5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pd7cl_bh/wheels/cc/ee/c4/68922955901918a9aaa82e828d4f7ee1ccfc861285277e79b7\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrERpwqWaNxY",
        "colab_type": "code",
        "outputId": "55282e9c-a902-4c98-c23f-70b15b47ce0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "############################################################################################\n",
        "# Herramientas varias\n",
        "############################################################################################\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import collections\n",
        "from collections import Counter\n",
        "from pprint import pprint\n",
        "############################################################################################\n",
        "# Herramientas de traductor\n",
        "############################################################################################\n",
        "from translate import Translator\n",
        "############################################################################################\n",
        "# Herramientas de spacy y procesaminto de lenguaje natural\n",
        "############################################################################################\n",
        "import spacy\n",
        "import es_core_news_sm\n",
        "from spacy import displacy\n",
        "############################################################################################\n",
        "# Herramientas de NLTK y procesaminto de lenguaje natural\n",
        "############################################################################################\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer,SnowballStemmer\n",
        "from nltk.corpus import wordnet as wn\n",
        "############################################################################################\n",
        "# Algoritmo de clustering k-mean\n",
        "############################################################################################\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans,AgglomerativeClustering,DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "############################################################################################\n",
        "# Herramientas de gensim y procesaminto de lenguaje natural\n",
        "############################################################################################\n",
        "from gensim import corpora\n",
        "from gensim.models import LsiModel\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "############################################################################################\n",
        "# Herramientas de graficos\n",
        "############################################################################################\n",
        "import matplotlib.pyplot as plt\n",
        "############################################################################################\n",
        "# Herramientas de scrapping\n",
        "############################################################################################\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#descargas necesarias para NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#inicio de objeto spacy\n",
        "nlp = es_core_news_sm.load()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCGJ4wN0aduL",
        "colab_type": "text"
      },
      "source": [
        "## **Lectura de DataSet de productos de Supermercado**\n",
        "\n",
        "Se obtiene el dataset de los productos de supermercados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9EJuCXza2K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cargamos en un dataframe el dataset de los productos de supermercados remplazando los valores nulos por espacios en blanco\n",
        "df = pd.read_csv(\"web_products.csv\")\n",
        "df = df.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDdsOfrebA0O",
        "colab_type": "code",
        "outputId": "cbd6b06c-cae4-4d83-918d-9e5b3e70bb36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "# se visualiza el contenido del dataframe\n",
        "df.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>cat3</th>\n",
              "      <th>web</th>\n",
              "      <th>brand</th>\n",
              "      <th>pname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14610</td>\n",
              "      <td>chocolates de leche</td>\n",
              "      <td>wong</td>\n",
              "      <td>orquidea</td>\n",
              "      <td>chocolate orquidea x 85 gr  leche c/coco - cho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10643</td>\n",
              "      <td>crema dental</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>oral-b</td>\n",
              "      <td>crema dental oral-b stages princess + cepillo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40669997</td>\n",
              "      <td>limpiadores</td>\n",
              "      <td>tottus</td>\n",
              "      <td>tottus</td>\n",
              "      <td>sacagrasa aroma naranja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40308095</td>\n",
              "      <td>galletas dulces</td>\n",
              "      <td>tottus</td>\n",
              "      <td>costa</td>\n",
              "      <td>galletas chocodonuts crunch six pack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5470</td>\n",
              "      <td>bebidas rehidratantes</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>powerade</td>\n",
              "      <td>bebida rehidratante powerade multifrutas botel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9911</td>\n",
              "      <td>gomitas y masticables</td>\n",
              "      <td>vivanda</td>\n",
              "      <td>mentos</td>\n",
              "      <td>goma de mascar mentos pure sin azúcar frasco 56gr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6146</td>\n",
              "      <td>vino tinto</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>trapiche</td>\n",
              "      <td>vino trapiche varietal malbec botella 750 ml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>46094</td>\n",
              "      <td></td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>ferymar</td>\n",
              "      <td>ají mirasol ferymar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3421</td>\n",
              "      <td>galletas</td>\n",
              "      <td>wong</td>\n",
              "      <td>nabisco</td>\n",
              "      <td>galletas oreo nabisco cookies and cream pack 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1321</td>\n",
              "      <td>galletas dulces</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>nestlé</td>\n",
              "      <td>galletas morochas bañadas con pasta sabor a ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>15302</td>\n",
              "      <td>bocaditos congelados</td>\n",
              "      <td>wong</td>\n",
              "      <td>wong</td>\n",
              "      <td>enpanaditas congeladas de pollo wong caja 16 unid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>568</td>\n",
              "      <td>cremas faciales</td>\n",
              "      <td>vivanda</td>\n",
              "      <td>nivea visage</td>\n",
              "      <td>cuidado facial nivea crema regeneradora noche ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>52703</td>\n",
              "      <td>alfombras</td>\n",
              "      <td>wong</td>\n",
              "      <td>krea</td>\n",
              "      <td>krea alfombra chindy 55x85 cm 3c oi19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>40956604</td>\n",
              "      <td>limpiadores</td>\n",
              "      <td>tottus</td>\n",
              "      <td>mr musculo</td>\n",
              "      <td>mr musculo vidrios fresca gatillo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>54550</td>\n",
              "      <td>box tarima queen</td>\n",
              "      <td>metro</td>\n",
              "      <td>rosen</td>\n",
              "      <td>rosen cama americana art 2 160 x 200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>18411</td>\n",
              "      <td>vino tinto</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>sierra cantabria</td>\n",
              "      <td>vino sierra cantabria protocolo tinto botella ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2896</td>\n",
              "      <td>jabón de lavar</td>\n",
              "      <td>vivanda</td>\n",
              "      <td>diamante</td>\n",
              "      <td>jabón para ropa diamante escamas bebé + jabón ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>41538254</td>\n",
              "      <td>collares y placas</td>\n",
              "      <td>tottus</td>\n",
              "      <td>wuf</td>\n",
              "      <td>collar de cuerdo color celeste talla m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>49476</td>\n",
              "      <td>reglas, tijeras y tajadores</td>\n",
              "      <td>metro</td>\n",
              "      <td>artesco</td>\n",
              "      <td>regla colors fun 30cm artesco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2230</td>\n",
              "      <td>té e infusiones</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>hornimans</td>\n",
              "      <td>anís hornimans caja 25un</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>42009</td>\n",
              "      <td>vino tinto</td>\n",
              "      <td>wong</td>\n",
              "      <td>kidia</td>\n",
              "      <td>vino tinto kidia gran reserva carmenere botell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>41526151</td>\n",
              "      <td>cera para depilar</td>\n",
              "      <td>tottus</td>\n",
              "      <td>depile</td>\n",
              "      <td>cera corporal rosa mosqueta para piel sensible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>14158</td>\n",
              "      <td>café</td>\n",
              "      <td>vivanda</td>\n",
              "      <td>colcafe</td>\n",
              "      <td>café instantáneo colcafé clásico frasco 85g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8108</td>\n",
              "      <td>limpiadores de otras superficies</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>broncex</td>\n",
              "      <td>limpiador metal broncex bronce y cobre botella...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>41189596</td>\n",
              "      <td>pan</td>\n",
              "      <td>tottus</td>\n",
              "      <td>molinos del mundo</td>\n",
              "      <td>pan de queso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>16508</td>\n",
              "      <td>vegetales en conserva</td>\n",
              "      <td>wong</td>\n",
              "      <td>valle fértil</td>\n",
              "      <td>espárragos verdes valle fértil frasco 360 g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>57605</td>\n",
              "      <td>labios</td>\n",
              "      <td>wong</td>\n",
              "      <td>mood matcher</td>\n",
              "      <td>mood matcher lipstick liquid matte 10 berry beret</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>40765308</td>\n",
              "      <td>aceituna ascolana</td>\n",
              "      <td>tottus</td>\n",
              "      <td>tottus</td>\n",
              "      <td>aceituna botija con pepa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>4627</td>\n",
              "      <td>pisco puro</td>\n",
              "      <td>wong</td>\n",
              "      <td>viejo tonel</td>\n",
              "      <td>pisco viejo tonel grand comod acholado botella...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>26957</td>\n",
              "      <td>piscinas y accesorios de playa</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>intex</td>\n",
              "      <td>inflable helado intex 70cmx32cm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         pid  ...                                              pname\n",
              "0      14610  ...  chocolate orquidea x 85 gr  leche c/coco - cho...\n",
              "1      10643  ...  crema dental oral-b stages princess + cepillo ...\n",
              "2   40669997  ...                           sacagrasa aroma naranja \n",
              "3   40308095  ...               galletas chocodonuts crunch six pack\n",
              "4       5470  ...  bebida rehidratante powerade multifrutas botel...\n",
              "5       9911  ...  goma de mascar mentos pure sin azúcar frasco 56gr\n",
              "6       6146  ...       vino trapiche varietal malbec botella 750 ml\n",
              "7      46094  ...                                ají mirasol ferymar\n",
              "8       3421  ...  galletas oreo nabisco cookies and cream pack 6...\n",
              "9       1321  ...  galletas morochas bañadas con pasta sabor a ch...\n",
              "10     15302  ...  enpanaditas congeladas de pollo wong caja 16 unid\n",
              "11       568  ...  cuidado facial nivea crema regeneradora noche ...\n",
              "12     52703  ...              krea alfombra chindy 55x85 cm 3c oi19\n",
              "13  40956604  ...                  mr musculo vidrios fresca gatillo\n",
              "14     54550  ...               rosen cama americana art 2 160 x 200\n",
              "15     18411  ...  vino sierra cantabria protocolo tinto botella ...\n",
              "16      2896  ...  jabón para ropa diamante escamas bebé + jabón ...\n",
              "17  41538254  ...             collar de cuerdo color celeste talla m\n",
              "18     49476  ...                      regla colors fun 30cm artesco\n",
              "19      2230  ...                           anís hornimans caja 25un\n",
              "20     42009  ...  vino tinto kidia gran reserva carmenere botell...\n",
              "21  41526151  ...     cera corporal rosa mosqueta para piel sensible\n",
              "22     14158  ...        café instantáneo colcafé clásico frasco 85g\n",
              "23      8108  ...  limpiador metal broncex bronce y cobre botella...\n",
              "24  41189596  ...                                       pan de queso\n",
              "25     16508  ...        espárragos verdes valle fértil frasco 360 g\n",
              "26     57605  ...  mood matcher lipstick liquid matte 10 berry beret\n",
              "27  40765308  ...                           aceituna botija con pepa\n",
              "28      4627  ...  pisco viejo tonel grand comod acholado botella...\n",
              "29     26957  ...                    inflable helado intex 70cmx32cm\n",
              "\n",
              "[30 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5n0PCGjaYWo",
        "colab_type": "text"
      },
      "source": [
        "## **Limpieza del nombre de producto**\n",
        "\n",
        "Se desarrolla una función donde se limpia el nombre del producto, se retira la marca, el nombre de la web, la unidad de medida, valores numéricos, etc.\n",
        "Se adiciona una columna al dataframe con el nombre de clean product, donde se encuentra el nombre del producto limpio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT5pMcDVbYvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lst_medida = [\"dt\",\"gr\",\"un\",\"kl\",\"kg\",\"ml\",\"mt\",\"cm\",\"oz\",\"oi\",\"plz\",\"bl\",\"unidades\",\"litro\",\"und\",\"unid\",\"talla\",\"ts\",\"ch\",\"pack\",\"lata\",\"latas\",\"bolsa\",\"bolsas\",\"botella\",\"botellas\",\"paquete\",\"paquetes\",\"caja\",\"frasco\",\"frascos\"]\n",
        "\n",
        "# se crea una funcion para limpiar el nombre del producto\n",
        "def clean_product(web,brand,name_prod):\n",
        "  #name_prod = translate(name_prod)\n",
        "  # se retira el nombre de la web\n",
        "  name_prod = str(name_prod).replace(str(web),\" \") \n",
        "  # se retira la marca\n",
        "  name_prod = str(name_prod).replace(str(brand),\" \") \n",
        "  # se retira los signos de puntuacion\n",
        "  for i in string.punctuation:\n",
        "    name_prod = str(name_prod).replace(i,\" \")\n",
        "  # se retira los numeros\n",
        "  name_prod = re.sub('x\\d', ' ', name_prod)\n",
        "  name_prod = re.sub('\\d', ' ', name_prod)\n",
        "  # se crea una bolsa de palabras sin stopword y unidades de medidas\n",
        "  bag_word = \"\"\n",
        "  for i in name_prod.split(\" \"):\n",
        "    if i not in stopwords.words('spanish') and i not in lst_medida and len(i)>1:\n",
        "    #if i not in lst_medida and len(i)>1:\n",
        "      bag_word = bag_word + \" \" + str(i)\n",
        "  # se valida que cada palabra de la bolsa tenga al menos un caracter\n",
        "  lst_word = []\n",
        "  for i in bag_word.split(\" \"):\n",
        "    if len(i)>1 and i not in lst_word:\n",
        "      lst_word.append(i)\n",
        "      \n",
        "  return \" \".join(lst_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDaTBoRmcaiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# se genera la función para crear el campo clean_product\n",
        "df['clean_product'] = df.apply(lambda x: clean_product(x['web'],x['brand'],x['pname']),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krLsOGnadOis",
        "colab_type": "code",
        "outputId": "73da08cd-d9a5-4df4-d9de-e8d3ed7f9d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>pid</th>\n",
              "      <th>cat3</th>\n",
              "      <th>web</th>\n",
              "      <th>brand</th>\n",
              "      <th>pname</th>\n",
              "      <th>clean_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14610</td>\n",
              "      <td>chocolates de leche</td>\n",
              "      <td>wong</td>\n",
              "      <td>orquidea</td>\n",
              "      <td>chocolate orquidea x 85 gr  leche c/coco - cho...</td>\n",
              "      <td>chocolate leche coco orqui</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10643</td>\n",
              "      <td>crema dental</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>oral-b</td>\n",
              "      <td>crema dental oral-b stages princess + cepillo ...</td>\n",
              "      <td>crema dental stages princess cepillo suave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>40669997</td>\n",
              "      <td>limpiadores</td>\n",
              "      <td>tottus</td>\n",
              "      <td>tottus</td>\n",
              "      <td>sacagrasa aroma naranja</td>\n",
              "      <td>sacagrasa aroma naranja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>40308095</td>\n",
              "      <td>galletas dulces</td>\n",
              "      <td>tottus</td>\n",
              "      <td>costa</td>\n",
              "      <td>galletas chocodonuts crunch six pack</td>\n",
              "      <td>galletas chocodonuts crunch six</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5470</td>\n",
              "      <td>bebidas rehidratantes</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>powerade</td>\n",
              "      <td>bebida rehidratante powerade multifrutas botel...</td>\n",
              "      <td>bebida rehidratante multifrutas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                               clean_product\n",
              "0           0  ...                  chocolate leche coco orqui\n",
              "1           1  ...  crema dental stages princess cepillo suave\n",
              "2           2  ...                     sacagrasa aroma naranja\n",
              "3           3  ...             galletas chocodonuts crunch six\n",
              "4           4  ...             bebida rehidratante multifrutas\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da_ir9Iecc4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# se graba una nueva version del dataset con el campo clean_product\n",
        "df.to_csv(\"web_clean_product.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOBl_ZRbd0W9",
        "colab_type": "text"
      },
      "source": [
        "## **Desarrollo del Agrupamiento de Productos**\n",
        "\n",
        "Se agruparan los productos a traves de las palabras que lo forman y por la frecuencia de las mismas en las oraciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqZ5CSCZdrun",
        "colab_type": "code",
        "outputId": "f517cebe-ec2f-47d8-cb00-baf3e47fa4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "# cargamos en un dataframe\n",
        "df = pd.read_csv(\"web_clean_product.csv\")\n",
        "df = df.replace(np.nan, '', regex=True)\n",
        "df_doc = df[[\"pid\",\"cat3\",\"web\",\"brand\",\"pname\",\"clean_product\"]]\n",
        "\n",
        "#df = pd.read_csv(\"web_clean_product_batch_cluster_450_v1.csv\")\n",
        "#df = df.replace(np.nan, '', regex=True)\n",
        "#df_doc = df[[\"pid\",\"cat3\",\"web\",\"brand\",\"pname\",\"clean_product\",\"cluster\"]]\n",
        "#df_doc = df_doc.loc[df[\"cluster\"]==19]\n",
        "#df_doc = df_doc[[\"pid\",\"cat3\",\"web\",\"brand\",\"pname\",\"clean_product\"]]\n",
        "\n",
        "\n",
        "df_doc.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>cat3</th>\n",
              "      <th>web</th>\n",
              "      <th>brand</th>\n",
              "      <th>pname</th>\n",
              "      <th>clean_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14610</td>\n",
              "      <td>chocolates de leche</td>\n",
              "      <td>wong</td>\n",
              "      <td>orquidea</td>\n",
              "      <td>chocolate orquidea x 85 gr  leche c/coco - cho...</td>\n",
              "      <td>chocolate leche coco orqui</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10643</td>\n",
              "      <td>crema dental</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>oral-b</td>\n",
              "      <td>crema dental oral-b stages princess + cepillo ...</td>\n",
              "      <td>crema dental stages princess cepillo suave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40669997</td>\n",
              "      <td>limpiadores</td>\n",
              "      <td>tottus</td>\n",
              "      <td>tottus</td>\n",
              "      <td>sacagrasa aroma naranja</td>\n",
              "      <td>sacagrasa aroma naranja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40308095</td>\n",
              "      <td>galletas dulces</td>\n",
              "      <td>tottus</td>\n",
              "      <td>costa</td>\n",
              "      <td>galletas chocodonuts crunch six pack</td>\n",
              "      <td>galletas chocodonuts crunch six</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5470</td>\n",
              "      <td>bebidas rehidratantes</td>\n",
              "      <td>plaza_vea</td>\n",
              "      <td>powerade</td>\n",
              "      <td>bebida rehidratante powerade multifrutas botel...</td>\n",
              "      <td>bebida rehidratante multifrutas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        pid  ...                               clean_product\n",
              "0     14610  ...                  chocolate leche coco orqui\n",
              "1     10643  ...  crema dental stages princess cepillo suave\n",
              "2  40669997  ...                     sacagrasa aroma naranja\n",
              "3  40308095  ...             galletas chocodonuts crunch six\n",
              "4      5470  ...             bebida rehidratante multifrutas\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQAy9bsOeTYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_tokenizer(text):\n",
        "    #tokenizes and stems the text\n",
        "    #doc = nlp(u\"\"+text)\n",
        "    tokens = word_tokenize(text)  \n",
        "    #tokens = [token.lemma_ for token in doc]\n",
        "    tokens = [t for t in tokens if t not in stopwords.words('spanish') and len(t.strip())>0]\n",
        "    #stemmer = PorterStemmer()\n",
        "    stemmer = SnowballStemmer('spanish')\n",
        "    tokens = [stemmer.stem(t) for t in tokens]\n",
        "    return tokens\n",
        "    #return lst_token \n",
        "    \n",
        "    \n",
        "def cluster_sentences(sentences, nb_of_clusters=5):\n",
        "  tfidf_vectorizer = TfidfVectorizer(tokenizer = word_tokenizer,\n",
        "                                     #stop_words = stopwords.words('spanish'),\n",
        "                                     encoding = u'utf-8',\n",
        "                                     ngram_range = (1, 3),\n",
        "                                     #ngram_range = (1, 4),\n",
        "                                     #strip_accents = 'unicode', \n",
        "                                     lowercase = True)\n",
        "  #builds a tf-idf matrix for the sentences\n",
        "  tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "  \n",
        "   \n",
        "  \n",
        "  #kmeans = KMeans(n_clusters=nb_of_clusters, init=\"k-means++\" , n_init = 10, max_iter = 100, random_state=550,n_jobs =30,algorithm = \"full\") #700 ,rs=550, 2444\n",
        "    \n",
        "  kmeans = KMeans(n_clusters=nb_of_clusters, init=\"k-means++\" , n_init = 10, max_iter = 100, random_state=550,n_jobs =30,algorithm = \"full\") #550 600 #2552 \n",
        "  \n",
        "  #kmeans = KMeans(n_clusters=nb_of_clusters, init=\"k-means++\" , n_init = 10, max_iter = 100, random_state=400,n_jobs =30,algorithm = \"full\") #450 #3652\n",
        "  \n",
        "  \n",
        "  \n",
        "  kmeans.fit(tfidf_matrix)\n",
        "  clusters = collections.defaultdict(list)\n",
        "  for i, label in enumerate(kmeans.labels_):\n",
        "    clusters[label].append(i)\n",
        "  return dict(clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m0TASZBeleY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_doc.columns\n",
        "s_pid = df_doc[\"pid\"].values\n",
        "s_cat3 = df_doc[\"cat3\"].values\n",
        "s_web = df_doc[\"web\"].values\n",
        "s_brand = df_doc[\"brand\"].values  \n",
        "s_product = df_doc[\"pname\"].values  \n",
        "s_clean_product = df_doc[\"clean_product\"].values # sin marca y sin web "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD9-TDRVev5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lst_product_cluster = [] \n",
        "nclusters= 650\n",
        "clusters = cluster_sentences(s_clean_product, nclusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JwY2TU1Uz5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for cluster in range(nclusters):\n",
        "    #print(\"cluster \",cluster,\":\")\n",
        "    for i,sentence in enumerate(clusters[cluster]):\n",
        "        #print(\"    \",s_clean_product[sentence],\" - \",s_web[sentence])\n",
        "        dict_cluster = {}\n",
        "        dict_cluster[\"pid\"] = s_pid[sentence]\n",
        "        dict_cluster[\"cat3\"] = s_cat3[sentence]\n",
        "        dict_cluster[\"web\"] = s_web[sentence]\n",
        "        dict_cluster[\"brand\"] = s_brand[sentence] \n",
        "        dict_cluster[\"pname\"] = s_product[sentence]\n",
        "        dict_cluster[\"clean_product\"] = s_clean_product[sentence] \n",
        "        dict_cluster[\"cluster\"] = cluster\n",
        "        lst_product_cluster.append(dict_cluster)\n",
        "        \n",
        "pd_cluster = pd.DataFrame(lst_product_cluster) \n",
        "pd_cluster.to_csv(\"web_clean_product_batch_cluster_650_v1.csv\") # modificar el ngrama range"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnTLlEDzdiQS",
        "colab_type": "text"
      },
      "source": [
        "## **Calculo de palabras en comun**\n",
        "\n",
        "Se desarrolla una función para calcular el porcentaje de similaridad entre palabras de una oración"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DT4WKvdfqcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def porcentaje_palabras_comun(pal1,pal2): \n",
        "  # initialize regex tokenizer\n",
        "  en_stop = set(stopwords.words('spanish'))\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  \n",
        "  tokensA = tokenizer.tokenize(pal1)\n",
        "  tokensA = [i for i in tokensA if not i in en_stop]\n",
        "  \n",
        "  tokensB = tokenizer.tokenize(pal2)\n",
        "  tokensB = [i for i in tokensB if not i in en_stop]\n",
        "  \n",
        "  \n",
        "  tokens = list(set(tokensA) & set(tokensB))\n",
        "  \n",
        "  palA = \"\"\n",
        "  for i in tokensA:\n",
        "    if i not in tokens:\n",
        "      palA += \" \" + i\n",
        "      \n",
        "  palB = \"\"\n",
        "  for i in tokensB:\n",
        "    if i not in tokens:\n",
        "      palB += \" \" + i\n",
        "  \n",
        "  return (len(tokens)/len(tokensA))*100, palA, palB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFQg8zy-gMQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cargamos en un dataframe\n",
        "df = pd.read_csv(\"web_clean_product_batch_cluster_650_v1.csv\")\n",
        "df = df[[\"brand\",\"cat3\",\"clean_product\",\"cluster\",\"pid\",\"pname\",\"web\"]] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88syk85DgkuA",
        "colab_type": "code",
        "outputId": "ec8fc250-8761-4cd8-ca19-7b14b1581ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "df_producto = df.loc[df[\"cluster\"]==205]\n",
        "df_producto.head(50)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>cat3</th>\n",
              "      <th>clean_product</th>\n",
              "      <th>cluster</th>\n",
              "      <th>pid</th>\n",
              "      <th>pname</th>\n",
              "      <th>web</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9572</th>\n",
              "      <td>cuatro estaciones</td>\n",
              "      <td>especias</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>10173633</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>tottus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9573</th>\n",
              "      <td>wong</td>\n",
              "      <td>condimentos y sazonadores</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>7539</td>\n",
              "      <td>comino molido wong sobre 18 g</td>\n",
              "      <td>wong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9574</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>otros condimentos</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>1094</td>\n",
              "      <td>comino sibarita molido frasco 40gr</td>\n",
              "      <td>plaza_vea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9575</th>\n",
              "      <td>kariño</td>\n",
              "      <td>otros condimentos</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>1628</td>\n",
              "      <td>comino kariño molido sobre 18gr</td>\n",
              "      <td>plaza_vea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>especias</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>10169975</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>tottus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9577</th>\n",
              "      <td>cuatro estaciones</td>\n",
              "      <td>especias</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>10173637</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>tottus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9578</th>\n",
              "      <td>badia</td>\n",
              "      <td>condimentos y sazonadores</td>\n",
              "      <td>comino molido badía onzas</td>\n",
              "      <td>205</td>\n",
              "      <td>14793</td>\n",
              "      <td>comino molido badía frasco 2 onzas</td>\n",
              "      <td>wong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9579</th>\n",
              "      <td>max &amp; mix</td>\n",
              "      <td>condimentos y sazonadores</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>7537</td>\n",
              "      <td>comino molido max &amp; mix sobre 20 g</td>\n",
              "      <td>wong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9580</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>otros condimentos</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>1608</td>\n",
              "      <td>comino sibarita molido paquete 6un</td>\n",
              "      <td>plaza_vea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9581</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>especias</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>433</td>\n",
              "      <td>comino sibarita molido paquete 6un</td>\n",
              "      <td>vivanda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9582</th>\n",
              "      <td>badia</td>\n",
              "      <td>condimentos y sazonadores</td>\n",
              "      <td>comino molido onza</td>\n",
              "      <td>205</td>\n",
              "      <td>7536</td>\n",
              "      <td>comino molido badia sobre 1 onza</td>\n",
              "      <td>wong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9583</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>condimentos y sazonadores</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>14788</td>\n",
              "      <td>comino molido sibarita frasco 40 g</td>\n",
              "      <td>wong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9584</th>\n",
              "      <td>kariño</td>\n",
              "      <td>otros condimentos</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>1658</td>\n",
              "      <td>comino kariño molido frasco 40gr</td>\n",
              "      <td>plaza_vea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9585</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>condimentos y sazonadores</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>7538</td>\n",
              "      <td>comino molido sibarita sobre 6 unid</td>\n",
              "      <td>wong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9586</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>especias</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>10169985</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>tottus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9587</th>\n",
              "      <td>sibarita</td>\n",
              "      <td>especias</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>542</td>\n",
              "      <td>comino sibarita molido frasco 40gr</td>\n",
              "      <td>vivanda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9588</th>\n",
              "      <td>max &amp; mix</td>\n",
              "      <td>condimentos y sazonadores</td>\n",
              "      <td>comino molido</td>\n",
              "      <td>205</td>\n",
              "      <td>14787</td>\n",
              "      <td>comino molido max &amp; mix frasco 43 g</td>\n",
              "      <td>wong</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  brand  ...        web\n",
              "9572  cuatro estaciones  ...     tottus\n",
              "9573               wong  ...       wong\n",
              "9574           sibarita  ...  plaza_vea\n",
              "9575             kariño  ...  plaza_vea\n",
              "9576           sibarita  ...     tottus\n",
              "9577  cuatro estaciones  ...     tottus\n",
              "9578              badia  ...       wong\n",
              "9579          max & mix  ...       wong\n",
              "9580           sibarita  ...  plaza_vea\n",
              "9581           sibarita  ...    vivanda\n",
              "9582              badia  ...       wong\n",
              "9583           sibarita  ...       wong\n",
              "9584             kariño  ...  plaza_vea\n",
              "9585           sibarita  ...       wong\n",
              "9586           sibarita  ...     tottus\n",
              "9587           sibarita  ...    vivanda\n",
              "9588          max & mix  ...       wong\n",
              "\n",
              "[17 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyu4KUQKiFfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lst_prod =[]\n",
        "for i,row1 in df_producto.iterrows():\n",
        "  for j,row2 in df_producto.iterrows():\n",
        "    if row1[\"clean_product\"] != row2[\"clean_product\"]:\n",
        "      \n",
        "      porc, palA, palB = porcentaje_palabras_comun(row1[\"clean_product\"],row2[\"clean_product\"])\n",
        "      porc2, palA2, palB2 = porcentaje_palabras_comun(row1[\"pname\"],row2[\"pname\"])\n",
        "      \n",
        "      porc3, palB3, palA3 = porcentaje_palabras_comun(row2[\"clean_product\"],row1[\"clean_product\"])\n",
        "      porc4, palB4, palA4 = porcentaje_palabras_comun(row2[\"pname\"],row1[\"pname\"])\n",
        "      \n",
        "      porc_med = ((porc+porc2+porc3+porc4)/4)\n",
        "      \n",
        "      if porc_med > 60 :\n",
        "        dict_prod = {}\n",
        "        dict_prod[\"pp_brand\"] = row1[\"brand\"]\n",
        "        dict_prod[\"pp_cat3\"] = row1[\"cat3\"]\n",
        "        dict_prod[\"pp_clean_product\"] = row1[\"clean_product\"]\n",
        "        dict_prod[\"pp_cluster\"] = row1[\"cluster\"]\n",
        "        dict_prod[\"pp_pid\"] = row1[\"pid\"]\n",
        "        dict_prod[\"pp_pname\"] = row1[\"pname\"]\n",
        "        dict_prod[\"pp_web\"] = row1[\"web\"] \n",
        "        dict_prod[\"porc_sim_palabra\"] = porc\n",
        "        dict_prod[\"porc_sim_palabra2\"] = porc2\n",
        "        dict_prod[\"porc_sim_palabra3\"] = porc3\n",
        "        dict_prod[\"porc_sim_palabra4\"] = porc4\n",
        "        dict_prod[\"porc_sim_palabra_prom\"] = porc_med\n",
        "        dict_prod[\"ps_brand\"] = row2[\"brand\"]\n",
        "        dict_prod[\"ps_cat3\"] = row2[\"cat3\"]\n",
        "        dict_prod[\"ps_clean_product\"] = row2[\"clean_product\"]\n",
        "        dict_prod[\"ps_cluster\"] = row2[\"cluster\"]\n",
        "        dict_prod[\"ps_pid\"] = row2[\"pid\"]\n",
        "        dict_prod[\"ps_pname\"] = row2[\"pname\"]\n",
        "        dict_prod[\"ps_web\"] = row2[\"web\"] \n",
        "        dict_prod[\"pp_dif_pal\"] = palA\n",
        "        dict_prod[\"ps_dif_pal\"] = palB\n",
        "        dict_prod[\"pp_dif_pal2\"] = palA2\n",
        "        dict_prod[\"ps_dif_pal2\"] = palB2\n",
        "        dict_prod[\"pp_dif_pal3\"] = palA3\n",
        "        dict_prod[\"ps_dif_pal3\"] = palB3\n",
        "        dict_prod[\"pp_dif_pal4\"] = palA4\n",
        "        dict_prod[\"ps_dif_pal4\"] = palB4\n",
        "        lst_prod.append(dict_prod)\n",
        "  #break\n",
        "  \n",
        "df_sp = pd.DataFrame(lst_prod)\n",
        "\n",
        "df_sp.head()\n",
        "df_sp.to_csv(\"web_producto_clean_cluster_porc_sim_v11.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFVj9jz4bLIG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iogVs349djad",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}